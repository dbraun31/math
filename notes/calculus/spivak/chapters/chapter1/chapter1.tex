\chapter{Basic Properties of Numbers}

\begin{quote}
    To be conscious that you are ignorant is a great step to knowledge.
    \hfill -- Benjamin Disraeli
\end{quote}

We're going to consider twelve properties of numbers, and the first nine are concerned
with addition and multiplication.

\section{Addition}

\begin{definition}
    Regard addition as an operation which can be performed on a pair of numbers, $a + b$.
\end{definition}

He argues it might be intuitive to want to define addition over a series of numbers, but
that series can just be broken down into summing of different pairs. This reveals that the
order of the summation yields equivalent results, which gives our first property:

\begin{property}[Associative law for addition]
    If $a,~b,$ and $c$ are any numbers, then
    $$
    a + (b + c) = (a + b) + c
    $$
\end{property}

This generalizes straightforwardly to $a_1 + \ldots + a_n$. He notes that a reasonable
approach to showing this extension is outlined in Problem 24. 

\subsection{Properties involving zero}

\begin{property}[Existence of an additive identity]\label{prop:additiveidentity}
    If $a$ is any number, then 
    $$
    a + 0 = 0 + a = a.
    $$
\end{property}

\begin{property}[Existence of additive inverses]\label{prop:additiveinverse}
    For every number $a$, there is a number $-a$ such that
    $$
    a + (-a) = (-a) + a = 0
    $$
\end{property}

We can now use these three properties to prove a simple assertion, which is that if a
number $x$ satisfies $a + x = a$, $x=0$.

\begin{alignat*}{3}
    &\text{If} \quad&  a + x &= a,\\
    &\text{then} \quad & (-a) + (a + x) &= (-a) + a = 0;\\
    &\text{hence} \quad & ((-a) + a) + x &= 0;\\
    &\text{hence} \quad & 0 + x &= 0\\
    &\text{hence} \quad & x &=0
\end{alignat*}

Ahhh that's pretty cool. He goes on to show that you can support basic algebraic maneuvers
with these three properties. 

\begin{property}[Commutative law for addition]
    If $a$ and $b$ are any numbers, then
    $$
    a + b = b + a
    $$
\end{property}

He goes on to say that commutative law doesn't hold for other types of relations (eg,
subtraction). But in order to have all algebra moves on the table, it's necessary to
introduce multiplication.

\section{Multiplication}

\begin{property}[Associative law of multiplication]
    If $a,~b$ and $c$ are any numbers, then
    $$
    a \cdot (b\cdot c) = (a \cdot b) \cdot c
    $$
\end{property}

\begin{property}[Existence of multiplicative identity]
    If $a$ is any number, then
    \begin{align*}
        a \cdot 1 = 1 \cdot a = a\\
        \text{Moreover,}~1 \neq 0
    \end{align*}
\end{property}

He's saying we have to list $1\neq 0$ because there's no way to prove based only on the
other properties---they would all hold if $0$ was the only number. 

\begin{property}[Existence of multiplicative inverses]\label{prop:multinverse}
    For every number $a \neq 0$, there is a number $a^{-1}$ such that
    $$
    a \cdot a^{-1} = a^{-1} \cdot a = 1
    $$
\end{property}

\begin{property}[Commutative law of multiplication]
    If $a$ and $b$ are any numbers, then
    $$
    a \cdot b = b \cdot a
    $$
\end{property}

Points out how necessary $a\neq 0$ is in Property \ref{prop:multinverse}, as there is no
number $0^{-1}$ satisfying $0 \cdot 0^{-1} = 1$. This is cool: just as how subtraction was
defined in terms of addition, division is defined in terms of multiplication. Note that
the usual form of an inverse (at least for an integer) is:

$$
a^{-1} = \frac{1}{a}
$$

So he says the symbol $a/b$ can be thought of as $a \cdot b^{-1}$. We can show that, as
long as $a\neq 0$, then for $a \cdot b = a \cdot c$, that $b = c$.

\begin{alignat*}{3}
    &\text{If}\quad& a\cdot b  &= 0~\text{and}~ a \neq 0,\\
    &\text{then}\quad&   a^{-1} \cdot (a \cdot b)  &= a^{-1} \cdot (a \cdot c);\\
    & \text{hence}\quad&  (a^{-1} \cdot a) \cdot b  &= (a^{-1} \cdot a) \cdot c;\\
    & \text{hence} \quad & 1 \cdot b &= 1 \cdot c;\\
    & \text{hence} \quad & b&=c.
\end{alignat*}

It also follows from Property \ref{prop:multinverse} that if $a \cdot b = 0$ then either
$a = 0$ or $b = 0$ (implied that this includes the possibility that they're both zero). We
can show that, if we know one of them \emph{isn't} zero, that the other one must be:

\begin{alignat*}{3}
    &\text{if} \quad& a \cdot b &= 0~\text{and}~ a \neq 0,\\
    & \text{then} \quad& a^{-1} \cdot (a \cdot b) &= 0;\\
    & \text{hence} \quad& (a^{-1} \cdot a) \cdot b &= 0;\\ 
    & \text{hence} \quad& 1 \cdot b &= 0; \\
    & \text{hence} \quad& b &=0.
\end{alignat*}

This concept of one or another variable must be equal to zero comes into play in the
familiar factoring of binomial situations (eg, $(x-1)(x-2) = 0$), where we know $x = 1$ or
$x = 2$.

\section{Distribution}

This next property gives us tremendous ability to prove lots of things:

\begin{property}[Distributive law]\label{prop:distributive}
    If $a,~b,$ and $c$ are any numbers, then 
    $$
    a \cdot (b + c) = a \cdot b + a \cdot c
    $$
\end{property}


With Property \ref{prop:distributive}, we can now show the only case when $a - b = b-a$:

\begin{alignat*}{3}
    &\text{If}\quad& a - b &= b - a, \\
    & \text{then}\quad& (a-b) + b &= (b-a) + b = b + (b-a);\\
    & \text{then}\quad& a &= b + b -a;\\
    & \text{then}\quad& a + a &= (b+b-a)+a = b+b;\\
    & \text{Consequently}\quad& a \cdot(1+1)&= b \cdot (1+1),\\
    &\text{and therefore}\quad& a &=b.
\end{alignat*}

\subsection{More zero stuff}

With Property \ref{prop:distributive}, we can do more reckoning around zero, such as
showing that $a \cdot 0 = 0$. (Some of this upcoming logic gets pretty nifty). The proof:

\begin{align}
    a \cdot 0 &= a \cdot (0+0) \label{step169} \\
              &= a\cdot0 + a \cdot 0\\
    (a\cdot 0) - (a \cdot 0) &= a \cdot 0 + a \cdot 0 - a \cdot 0\\
    0 &= a \cdot 0
\end{align}

Step \ref{step169} is by Proposition \ref{prop:additiveidentity} (the additive identity).

He next talks about using Property \ref{prop:distributive} to show why multiplying two
negative numbers equals a positive number. Starting with proving that $(-a) \cdot b = -(a
\cdot b)$:

\begin{align}
    (-a) \cdot b + a \cdot b &= [(-a) + a] \cdot b \label{step181}\\
                             &= 0 \cdot b\\
                             &= 0
\end{align}

He says then by adding $-(a \cdot b)$ to both sides, we see that $(-a) \cdot b = -(a \cdot
b)$. A few things I'm learning about proofs here:

\begin{itemize}

    \item I think knowing where to get started in proofs is one of the hardest parts. Here
        he's implicitly starting with applying Proposition \ref{prop:additiveinverse}
        (additive inverse), by relying on the logic that, if two quantities are the same,
        then adding the quantity to its inverse should reduce to zero. So if $(-a) \cdot b
        = -(a \cdot b)$, then we should be able to show that $(-a) \cdot b + a\cdot b =
        0$.
    \item When we get to the end ($=0$), that's actually a shorthand for the initial
        expression equaling whatever we've arrived at (ie, $(-a) \cdot b + a \cdot b =
        0$). So when he says something like "adding $-(a\cdot b)$ to both sides, that
        really means $(-a) \cdot b + a \cdot b - (a \cdot b) = 0 - (a \cdot b)$, which
        reduces to $(-a) \cdot b = - (a \cdot b)$.

\end{itemize}

We then go on to prove that $(-a) \cdot (-b) = a \cdot b$:

\begin{align}
    (-a) \cdot (-b) + [-(a \cdot b)] &= (-a) \cdot (-b) + (-a) \cdot b\label{step209}\\
                                 &= -a \cdot (-b + b)\label{step210}\\
                                 &= -a \cdot 0 \label{step211}\\
                                 &= 0 \\
    (-a) \cdot (-b) + [-(a \cdot b)] + (a \cdot b) &= 0 + (a\cdot b)\\
    (-a) \cdot (-b) &= a \cdot b
\end{align}

Step \ref{step209} applies Proposition \ref{prop:additiveinverse} and applies the previous
proof that $(-a) \cdot b = -(a \cdot b)$. Step \ref{step210} applies Proposition
\ref{prop:distributive}, and step \ref{step211} applies Proposition
\ref{prop:additiveinverse}. He notes that this last proof is a \emph{consequence} of the
proposition---it simply follows from them once they're established. Goes on to hype up
Proposition \ref{prop:distributive} a bit more, showing how essential it is for basic
algebraic operations like factoring and multiplication.

\section{Inequalities}

Inequalities apparently feature prominently in calculus. Numbers satisfying $a > 0$ are
called \textbf{positive}, while those satisfying $a < 0$ are called \textbf{negative}. If
we denote the collection of all positive numbers with $P$, we can state the remaining
three propositions in terms of $P$:

\begin{property}[Trichotomy law]\label{prop:trichotomy}
    For every number $a$, one and only one of the following holds:
    \begin{enumerate}[label=(\roman*), leftmargin = 3em]
        \item $a = 0$,
        \item $a$ is in the collection $P$,
        \item $-a$ is in the collection $P$.
    \end{enumerate}
\end{property}

\begin{property}[Closure under addition]\label{prop:addclosure}
    If $a$ and $b$ are in $P$, then $a + b$ is in $P$
\end{property}

\begin{property}[Closure under multiplication]\label{prop:multclosure}
    If $a$ and $b$ are in $P$, then $a \cdot b$ is in $P$.
\end{property}


He says these properties should be paired with the following definitions:

\begin{alignat*}{3}
    &a > b \quad & \text{if} \quad & a - b \text{ is in } P;\\
    & a < b \quad & \text{if} \quad & b>a;\\
    & a \geq b \quad & \text{if} \quad & a > b \text{ or } a = b; \\
    & a \leq b \quad & \text{ if } \quad & a < b \text{ or } a = b.
\end{alignat*}

The first one here is the only one that's a bit tricky, which is essentially saying that
as long as the difference is positive, then we can say $a > b$. He also points out that $a
> 0$ if and only if $a$ is in $P$.

Glossing over some details. He goes on to say that if $a<b$ and $b<c$, then $a<c$. He gets
there with the following logic. First, suppose $a<b$ and $b<c$. Then

\begin{alignat*}{3}
    &\quad&& b-a~\text{is in}~P,\\
    &\text{and}\quad&& c-b~\text{is in}~P,\\
    & \text{so}\quad&& c-a = (c-b) + (b-a)~\text{is in}~P.
\end{alignat*}

Yea this logic of ``something minus something is positive'' is a little tricky. Let's zoom
in on $b-a$ is in $P$ provided that $a<b$. What we \emph{don't} have is $b>a>0$. If $b\in
P$, then the only constraint on $a$ is $a<b$---ie, $a$ can be negative because, for
example, $10 - (-5) > 0$. If $b < 0$, then $a < b$ still satisfies $b-a \in P$. 

He also shows, by Property \ref{prop:multclosure}, that $ab > 0$ if $a>0,~b>0$ and also if
$a<0,~b<0$. Thus, $a^2>0$ if $a \neq 0$.
The fact that $-a >0$ if $a < 0$ sets us up to define the absolute value function:

\begin{definition}[Absolute Value]
    $$
    \lvert a \rvert = \begin{cases}
        a, & a \geq 0\\
        -a, & a \leq 0
    \end{cases}
    $$
\end{definition}

He says the most straightforward way to deal with absolute values is to treating several
cases separately.

\begin{theorem}
    For all real numbers $a$ and $b$, we have
    $$
    \lvert a + b \rvert \leq \lvert a\rvert + \lvert b \rvert
    $$
\end{theorem}

\begin{proof}
    Consider four cases:
    \begin{alignat*}{4}
        &(1)\quad\quad&& a \geq 0, \quad & b \geq 0;\\
        &(2)\quad\quad && a \geq 0, \quad & b \leq 0;\\
        &(3)\quad\quad && a \leq 0, \quad & b \geq 0;\\
        &(4)\quad\quad && a \leq 0, \quad & b \leq 0;\\
    \end{alignat*} 

    For case (1), we see $\lvert a + b \rvert = \lvert a \rvert + \lvert b \rvert$.
    For case (4), we have $a+b \leq 0$, and again equality holds:
    \[
    \lvert a + b \rvert = -(a+b) = -a + (-b) = \lvert a \rvert + \lvert b \rvert
\]
    \emph{My note:} Again with proofs, it's a little obtuse to me where the reasoning
    behind the initial claim $a+b \leq 0$ comes from. Like I can clearly see that it's
    true, but I don't know how I would have generated that as a starting point.

    Case (2) starts to get tricky. He says we must prove that
    \[
    \lvert a + b \rvert \leq a - b
    \]  
    It took me a minute to see where this comes from. I understand the right side of the
    inequality as being the result of passing the original expression ($\lvert a \rvert +
    \lvert b \rvert$) through the absolute value function for $a \geq 0,~b \leq 0$. He
    then proceeds to check whether this inequality holds true for cases where $a + b \geq 0$
    and $a + b \leq 0$. For the first case $a + b \geq 0$,
    \begin{align*}
        a + b &\leq a - b\\
        b &\leq -b
    \end{align*}
    Which is true when $b \leq 0$. Next, for $a + b \leq 0$ we show that
    \begin{align*}
        -a - b &\leq a - b\\
        -a &\leq a
    \end{align*}

    It's hard for me to see where $-a - b$ comes from. Maybe it's something like
    \begin{align*}
        a + b &\leq 0\\
        \lvert a + b \rvert &= -(a + b)\\
        &= -a + (-b)
    \end{align*}

    Yea best I can tell that's it. Just gotta think back to the functional form of the
    absolute value function and apply a negative sign to any input less than zero. And so
    this is an example of what he alluded to above, where one needs to treat absolute
    values with respect to several different cases that revolve around zero.
        
\end{proof}

Left off right after this proof.
